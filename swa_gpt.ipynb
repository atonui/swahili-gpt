{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvQn9NY077INz5UTUgrZpe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atonui/swahili-gpt/blob/main/swa_gpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Swahili-GPT\n",
        "- A simple character level transformer based LLM trained on a Swahili dataset."
      ],
      "metadata": {
        "id": "nZvhfs91jrcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the training dataset\n",
        "!wget https://raw.githubusercontent.com/atonui/pds/refs/heads/main/swahili_data/train.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-yFDZfe5QZ9",
        "outputId": "195bf509-adca-4090-84ac-bc473b21fe30"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-21 07:49:59--  https://raw.githubusercontent.com/atonui/pds/refs/heads/main/swahili_data/train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7564413 (7.2M) [text/plain]\n",
            "Saving to: ‘train.txt’\n",
            "\n",
            "\rtrain.txt             0%[                    ]       0  --.-KB/s               \rtrain.txt           100%[===================>]   7.21M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-08-21 07:49:59 (146 MB/s) - ‘train.txt’ saved [7564413/7564413]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read it to inspect it\n",
        "with open('train.txt', 'r') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "UhB5WPU47Ou7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Length of dataset in characters: ', len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UxSd4krhuOa",
        "outputId": "c99bf84e-a6bc-4d8a-d1d9-e421523fe5f6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of dataset in characters:  7522342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRigK2Eph4gQ",
        "outputId": "17e0511e-9991-4481-a6b3-d86caa5ded31"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿ taarifa hiyo ilisema kuwa ongezeko la joto la maji juu ya wastani katikati ya bahari ya  inaashiria kuwepo kwa mvua za el nino  hadi mwishoni mwa april ishirini moja sifuri imeelezwa kuwa ongezeko la joto magharibi mwa bahari ya hindi linatarajiwa kuhamia katikati ya bahari hiyo hali ambayo itasababisha pepo kutoka kaskazini mashariki kuvuma kuelekea bahari ya hindi \n",
            " aidha ilisema kuwa mwelekeo wa kupungua kwa joto kusini mashariki mwa bahari ya atlantic  kusababisha pepo kutoka magharibi kuvuma kuelekea magharibi mwa tanzania katika maeneo ya ziwa victoria \n",
            " mwelekeo wa mvua wa septemba hadi desemba ishirini sifuri tisa unatarajiwa kuwa katika namna tofauti ambapo baadhi ya maeneo yanaweza kunufaika huku mengine  \n",
            " ilifafanua kuwa msimu wa vuli  maeneo ambayo hupata mvua mara mbili ambayo ni kaskazini mwa nchi ikiwa ni nyanda za juu kaskazini mashariki kanda ya ziwa victoria na pwani ya kaskazini \n",
            " katika maeneo hayo mvua zinatarajiwa kunyesha wiki ya pili na tatu ya septemba mwaka\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get a sorted list of all the characters in the text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(\"There are\", vocab_size, \"unique characters in this text.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRhQYJhSh8q4",
        "outputId": "1161db1f-14f2-472f-afe1-b4cd80004fa7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " abcdefghijklmnopqrstuvwxyz﻿\n",
            "There are 29 unique characters in this text.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenisation\n",
        "- Represent characters as integers (vectors) so the model can manipulate them.\n",
        "- The below tokeniser is simple, it just translates a character to an integer.\n",
        "- There are more sophisticated tokenisers out there, we shall experiment with them."
      ],
      "metadata": {
        "id": "YJyI7xQQimZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "print(encode(\"joto jingi\"))\n",
        "print(decode(encode(\"joto jingi\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEcJKxRMiXo4",
        "outputId": "ec6b04e3-8079-4c70-fb30-b2a78ca6816a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11, 16, 21, 16, 1, 11, 10, 15, 8, 10]\n",
            "joto jingi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode([14, 19, 24, 19, 1, 16, 17, 18, 11, 13]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSibstVvl-19",
        "outputId": "a10081a1-d5ee-4f87-c158-282591a6a692"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mrwr opqjl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we're going to encode the entire dataset and store it into a torch.Tensor\n",
        "import torch\n",
        "train_data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(train_data.shape, train_data.type,'\\n')\n",
        "print(train_data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzexWCVBnuuK",
        "outputId": "793d1f20-9b3f-489e-8f65-9d79dab58b4d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7522342]) <built-in method type of Tensor object at 0x7c85deec5bd0> \n",
            "\n",
            "tensor([28,  1, 21,  2,  2, 19, 10,  7,  2,  1,  9, 10, 26, 16,  1, 10, 13, 10,\n",
            "        20,  6, 14,  2,  1, 12, 22, 24,  2,  1, 16, 15,  8,  6, 27,  6, 12, 16,\n",
            "         1, 13,  2,  1, 11, 16, 21, 16,  1, 13,  2,  1, 14,  2, 11, 10,  1, 11,\n",
            "        22, 22,  1, 26,  2,  1, 24,  2, 20, 21,  2, 15, 10,  1, 12,  2, 21, 10,\n",
            "        12,  2, 21, 10,  1, 26,  2,  1,  3,  2,  9,  2, 19, 10,  1, 26,  2,  1,\n",
            "         1, 10, 15,  2,  2, 20,  9, 10, 19, 10,  2,  1, 12, 22, 24,  6, 17, 16,\n",
            "         1, 12, 24,  2,  1, 14, 23, 22,  2,  1, 27,  2,  1,  6, 13,  1, 15, 10,\n",
            "        15, 16,  1,  1,  9,  2,  5, 10,  1, 14, 24, 10, 20,  9, 16, 15, 10,  1,\n",
            "        14, 24,  2,  1,  2, 17, 19, 10, 13,  1, 10, 20,  9, 10, 19, 10, 15, 10,\n",
            "         1, 14, 16, 11,  2,  1, 20, 10,  7, 22, 19, 10,  1, 10, 14,  6,  6, 13,\n",
            "         6, 27, 24,  2,  1, 12, 22, 24,  2,  1, 16, 15,  8,  6, 27,  6, 12, 16,\n",
            "         1, 13,  2,  1, 11, 16, 21, 16,  1, 14,  2,  8,  9,  2, 19, 10,  3, 10,\n",
            "         1, 14, 24,  2,  1,  3,  2,  9,  2, 19, 10,  1, 26,  2,  1,  9, 10, 15,\n",
            "         5, 10,  1, 13, 10, 15,  2, 21,  2, 19,  2, 11, 10, 24,  2,  1, 12, 22,\n",
            "         9,  2, 14, 10,  2,  1, 12,  2, 21, 10, 12,  2, 21, 10,  1, 26,  2,  1,\n",
            "         3,  2,  9,  2, 19, 10,  1,  9, 10, 26, 16,  1,  9,  2, 13, 10,  1,  2,\n",
            "        14,  3,  2, 26, 16,  1, 10, 21,  2, 20,  2,  3,  2,  3, 10, 20,  9,  2,\n",
            "         1, 17,  6, 17, 16,  1, 12, 22, 21, 16, 12,  2,  1, 12,  2, 20, 12,  2,\n",
            "        27, 10, 15, 10,  1, 14,  2, 20,  9,  2, 19, 10, 12, 10,  1, 12, 22, 23,\n",
            "        22, 14,  2,  1, 12, 22,  6, 13,  6, 12,  6,  2,  1,  3,  2,  9,  2, 19,\n",
            "        10,  1, 26,  2,  1,  9, 10, 15,  5, 10,  1,  0,  1,  2, 10,  5,  9,  2,\n",
            "         1, 10, 13, 10, 20,  6, 14,  2,  1, 12, 22, 24,  2,  1, 14, 24,  6, 13,\n",
            "         6, 12,  6, 16,  1, 24,  2,  1, 12, 22, 17, 22, 15,  8, 22,  2,  1, 12,\n",
            "        24,  2,  1, 11, 16, 21, 16,  1, 12, 22, 20, 10, 15, 10,  1, 14,  2, 20,\n",
            "         9,  2, 19, 10, 12, 10,  1, 14, 24,  2,  1,  3,  2,  9,  2, 19, 10,  1,\n",
            "        26,  2,  1,  2, 21, 13,  2, 15, 21, 10,  4,  1,  1, 12, 22, 20,  2,  3,\n",
            "         2,  3, 10, 20,  9,  2,  1, 17,  6, 17, 16,  1, 12, 22, 21, 16, 12,  2,\n",
            "         1, 14,  2,  8,  9,  2, 19, 10,  3, 10,  1, 12, 22, 23, 22, 14,  2,  1,\n",
            "        12, 22,  6, 13,  6, 12,  6,  2,  1, 14,  2,  8,  9,  2, 19, 10,  3, 10,\n",
            "         1, 14, 24,  2,  1, 21,  2, 15, 27,  2, 15, 10,  2,  1, 12,  2, 21, 10,\n",
            "        12,  2,  1, 14,  2,  6, 15,  6, 16,  1, 26,  2,  1, 27, 10, 24,  2,  1,\n",
            "        23, 10,  4, 21, 16, 19, 10,  2,  1,  0,  1, 14, 24,  6, 13,  6, 12,  6,\n",
            "        16,  1, 24,  2,  1, 14, 23, 22,  2,  1, 24,  2,  1, 20,  6, 17, 21,  6,\n",
            "        14,  3,  2,  1,  9,  2,  5, 10,  1,  5,  6, 20,  6, 14,  3,  2,  1, 10,\n",
            "        20,  9, 10, 19, 10, 15, 10,  1, 20, 10,  7, 22, 19, 10,  1, 21, 10, 20,\n",
            "         2,  1, 22, 15,  2, 21,  2, 19,  2, 11, 10, 24,  2,  1, 12, 22, 24,  2,\n",
            "         1, 12,  2, 21, 10, 12,  2,  1, 15,  2, 14, 15,  2,  1, 21, 16,  7,  2,\n",
            "        22, 21, 10,  1,  2, 14,  3,  2, 17, 16,  1,  3,  2,  2,  5,  9, 10,  1,\n",
            "        26,  2,  1, 14,  2,  6, 15,  6, 16,  1, 26,  2, 15,  2, 24,  6, 27,  2,\n",
            "         1, 12, 22, 15, 22,  7,  2, 10, 12,  2,  1,  9, 22, 12, 22,  1, 14,  6,\n",
            "        15,  8, 10, 15,  6,  1,  1,  0,  1, 10, 13, 10,  7,  2,  7,  2, 15, 22,\n",
            "         2,  1, 12, 22, 24,  2,  1, 14, 20, 10, 14, 22,  1, 24,  2,  1, 23, 22,\n",
            "        13, 10,  1,  1, 14,  2,  6, 15,  6, 16,  1,  2, 14,  3,  2, 26, 16,  1,\n",
            "         9, 22, 17,  2, 21,  2,  1, 14, 23, 22,  2,  1, 14,  2, 19,  2,  1, 14,\n",
            "         3, 10, 13, 10,  1,  2, 14,  3,  2, 26, 16,  1, 15, 10,  1, 12,  2, 20,\n",
            "        12,  2, 27, 10, 15, 10,  1, 14, 24,  2,  1, 15,  4,  9, 10,  1, 10, 12,\n",
            "        10, 24,  2,  1, 15, 10,  1, 15, 26,  2, 15,  5,  2,  1, 27,  2,  1, 11,\n",
            "        22, 22,  1, 12,  2, 20, 12,  2, 27, 10, 15, 10,  1, 14,  2, 20,  9,  2,\n",
            "        19, 10, 12, 10,  1, 12,  2, 15,  5,  2,  1, 26,  2,  1, 27, 10, 24,  2,\n",
            "         1, 23, 10,  4, 21, 16, 19, 10,  2,  1, 15,  2,  1, 17, 24,  2, 15, 10,\n",
            "         1, 26,  2,  1, 12,  2, 20, 12,  2, 27, 10, 15, 10,  1,  0,  1, 12,  2,\n",
            "        21, 10, 12,  2,  1, 14,  2,  6, 15,  6, 16,  1,  9,  2, 26, 16,  1, 14,\n",
            "        23, 22,  2,  1, 27, 10, 15,  2, 21,  2, 19,  2, 11, 10, 24,  2,  1, 12,\n",
            "        22, 15, 26,  6, 20,  9,  2,  1, 24, 10, 12, 10,  1, 26,  2,  1, 17, 10,\n",
            "        13, 10,  1, 15,  2,  1, 21,  2, 21, 22,  1, 26,  2,  1, 20,  6, 17, 21,\n",
            "         6, 14,  3,  2,  1, 14, 24,  2, 12,  2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test dataset\n",
        "!wget https://raw.githubusercontent.com/atonui/pds/refs/heads/main/swahili_data/test.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_LNLRnar98n",
        "outputId": "2d88d36f-959d-4628-d390-587e10814727"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-21 07:50:12--  https://raw.githubusercontent.com/atonui/pds/refs/heads/main/swahili_data/test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 686306 (670K) [text/plain]\n",
            "Saving to: ‘test.txt’\n",
            "\n",
            "\rtest.txt              0%[                    ]       0  --.-KB/s               \rtest.txt            100%[===================>] 670.22K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-08-21 07:50:12 (28.4 MB/s) - ‘test.txt’ saved [686306/686306]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read it to inspect it\n",
        "with open('test.txt', 'r') as f:\n",
        "    test = f.read()"
      ],
      "metadata": {
        "id": "xuWYhPOLwF0T"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode test dataset into a tensor\n",
        "test_data = torch.tensor(encode(test), dtype=torch.long)\n",
        "print(test_data.shape, test_data.type, '\\n')\n",
        "print(test_data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMVNx7fVz_0_",
        "outputId": "27377f3d-0c79-4e69-b540-d2c011f56c84"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([682933]) <built-in method type of Tensor object at 0x7c85dfbac4b0> \n",
            "\n",
            "tensor([28,  1,  9, 22, 26, 16,  1,  2, 13, 10, 20, 10, 20, 10, 21, 10, 27,  2,\n",
            "         1, 12, 22, 24,  2,  1,  9,  2, 12, 22,  9, 16, 11, 10, 24,  2,  1,  3,\n",
            "         2, 13, 10,  1,  2, 13, 10, 17,  6, 24,  2,  1, 12,  2, 19,  2, 21,  2,\n",
            "        20, 10,  1, 21, 22, 17, 22,  1, 15,  2,  1, 12, 22, 21,  2, 12, 10, 24,\n",
            "         2,  1, 12, 22, 20,  2, 10, 15, 10,  1,  3, 10, 13,  2,  1, 12, 22,  7,\n",
            "         2,  9,  2, 14, 22,  1, 15, 10,  1, 12, 10, 21, 22,  1,  8,  2, 15, 10,\n",
            "         1,  1,  0,  1,  2, 12, 10,  6, 13,  6, 27,  6,  2,  1, 20, 10, 12, 22,\n",
            "         1, 26,  2,  1, 21, 22, 12, 10, 16,  1,  2, 13, 10, 20,  6, 14,  2,  1,\n",
            "         2, 13, 10, 17, 10,  8, 10, 24,  2,  1, 20, 10, 14, 22,  1, 15,  2,  1,\n",
            "        20, 20, 17,  1, 20,  2, 13, 22, 14,  1, 12, 10, 20,  2, 10,  1,  2, 14,\n",
            "         3,  2, 26,  6,  1,  2, 13, 10, 14, 21,  2, 12,  2,  1, 12, 22,  7, 10,\n",
            "        12,  2,  1, 12,  2, 21, 10, 12,  2,  1, 16,  7, 10, 20, 10,  1, 27,  2,\n",
            "         1, 21, 22, 14,  6,  1,  9, 10, 26, 16,  1, 15,  2,  1,  2, 13, 10,  7,\n",
            "        10, 12,  2,  1,  9,  2, 17, 16,  1, 16, 12, 21, 16,  3,  2,  1, 12, 22,\n",
            "        14, 10,  1, 14, 24,  2, 12,  2,  1, 11,  2, 15,  2,  1, 12, 22, 21,  6,\n",
            "        12,  6, 13,  6, 27,  2,  1,  2,  8, 10, 27, 16,  1, 13,  2,  1, 14, 17,\n",
            "         6, 13,  6, 13,  6, 27, 10,  1,  9, 22, 26, 16,  1,  0,  1,  2, 13, 10,\n",
            "         5,  2, 10,  1, 12, 22, 24,  2,  1,  3,  2,  2,  5,  2,  1, 26,  2,  1,\n",
            "        12, 22,  7, 10, 12,  2,  1,  9,  2, 17, 16,  1,  2, 13, 10,  2, 14,  3,\n",
            "        10, 24,  2,  1, 15,  2,  1,  3, 24,  2, 15,  2,  1, 12, 10, 20,  2, 10,\n",
            "         1, 12, 22, 24,  2,  1,  2, 15,  2,  9, 10, 21,  2, 11, 10,  1, 12, 22,\n",
            "         7,  2, 15, 26,  2,  1, 14,  2, 19,  6, 12,  6,  3, 10, 20,  9, 16,  1,\n",
            "        14,  2,  4,  9,  2,  4,  9,  6,  1, 12, 24,  6, 15, 26,  6,  1, 14,  2,\n",
            "         6, 13,  6, 27, 16,  1, 26,  2,  1, 21, 22,  9, 22, 14,  2,  1, 27,  2,\n",
            "        12,  6,  1,  9, 10, 23, 26, 16,  1,  2, 13, 10, 14, 17,  2,  1, 12,  2,\n",
            "        19,  2, 21,  2, 20, 10,  1, 21, 22, 17, 22,  1,  1, 15,  2,  1,  3,  2,\n",
            "         2,  5,  2, 26,  6,  1, 14, 17,  6, 13,  6, 13,  6, 27, 10,  1,  9, 22,\n",
            "        26, 16,  1,  2, 15,  8,  6,  2, 15,  5, 10, 12,  2,  1, 14,  2,  6, 13,\n",
            "         6, 27, 16,  1,  0,  1,  2, 13, 10,  5,  2, 10,  1, 12, 22, 24,  2,  1,\n",
            "        12,  2,  3, 13,  2,  1, 26,  2,  1, 12, 22, 21, 10,  2,  1, 20,  2, 10,\n",
            "        15, 10,  1,  2, 13, 10, 19, 22,  9, 22, 20, 10, 24,  2,  1, 12, 24,  6,\n",
            "        15,  5,  2,  1, 14, 20, 10, 12, 10, 21, 10, 15, 10,  1, 12, 22, 20, 24,\n",
            "         2, 13, 10,  1,  9, 10, 23, 26, 16,  1,  2, 13, 10, 16, 15,  5, 16, 12,\n",
            "         2,  1, 12, 22,  6, 13,  6, 12,  6,  2,  1, 14,  2,  6, 15,  6, 16,  1,\n",
            "        26,  2,  1, 14, 10, 12, 16,  4,  9,  6, 15, 10,  1,  5,  2, 19,  1,  6,\n",
            "        20,  1, 20,  2, 13,  2,  2, 14,  1,  0,  1, 20, 10, 21,  2, 20,  2,  9,\n",
            "         2, 22,  1, 12,  2, 21, 10, 12,  2,  1, 14,  2, 10, 20,  9,  2,  1, 26,\n",
            "         2, 15,  8, 22,  1, 15, 10,  1, 21, 22, 12, 10, 16,  1, 13,  2,  1,  2,\n",
            "        11,  2,  3, 22,  1,  2, 14,  3,  2, 13, 16,  1, 15, 10, 13, 10,  7,  2,\n",
            "        15, 26, 10, 24,  2,  1, 15, 10, 12, 10, 24,  2,  1, 14, 20, 10, 12, 10,\n",
            "        21, 10, 15, 10,  1,  2, 13, 10, 12, 22, 11,  2,  1, 16,  7, 10, 20,  2,\n",
            "         1, 14, 14, 16, 11,  2,  1, 24,  2,  1, 21, 22, 14,  6,  1, 15,  2,  1,\n",
            "        12, 22, 15, 10, 21,  2, 12,  2,  1, 15, 10,  6, 15,  5,  6,  1, 16,  7,\n",
            "        10, 20, 10,  1, 27,  2, 16,  1,  9, 22, 12, 22,  1, 14, 21, 16,  2,  1,\n",
            "         9, 16, 21, 22,  3,  2,  1,  2, 12, 10, 24,  2,  1,  2, 14,  6, 17,  2,\n",
            "        15,  5,  2,  1,  6, 15,  6, 16,  1, 13,  2,  1, 12, 22, 21, 16, 13,  6,\n",
            "         2,  1,  9, 16, 21, 22,  3,  2,  1,  9, 10, 26, 16,  1, 12, 24,  2,  1,\n",
            "        24,  2, 10, 20, 13,  2, 14,  1, 15,  5, 10,  4,  9, 16,  1, 12, 10, 21,\n",
            "        22,  1, 14, 22,  9, 10, 14, 22,  1, 20,  2, 15,  2,  1,  2, 13, 10,  5,\n",
            "         2, 10,  1,  3, 24,  2, 15,  2,  1,  7,  2, 19, 10, 11,  2, 13,  2,  1,\n",
            "         0,  1,  2, 13, 10,  5,  2, 10,  1, 12, 22, 24,  2,  1,  3,  2,  2,  5,\n",
            "         2,  1, 26,  2,  1, 12, 22,  7, 10, 12,  2,  1, 12,  2, 21, 10, 12,  2,\n",
            "         1, 21, 22, 14,  6,  1,  9, 10, 26, 16,  1,  2, 13, 10, 17,  6, 24,  2,\n",
            "         1, 12,  2, 19,  2, 21,  2, 20, 10,  1, 27, 10, 13,  6,  1, 27, 10, 13,\n",
            "         6,  1, 15,  2,  1, 12, 22,  2, 14,  3, 10, 24,  2,  1,  2, 20,  2, 10,\n",
            "        15, 10,  1, 10, 13, 10,  1,  2, 24,  6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# validation dataset\n",
        "!wget https://raw.githubusercontent.com/atonui/pds/refs/heads/main/swahili_data/valid.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn8P7PFyxfkp",
        "outputId": "fe95d54b-4a0f-45f4-db5a-e43577d535a7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-21 07:50:12--  https://raw.githubusercontent.com/atonui/pds/refs/heads/main/swahili_data/valid.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 655979 (641K) [text/plain]\n",
            "Saving to: ‘valid.txt’\n",
            "\n",
            "\rvalid.txt             0%[                    ]       0  --.-KB/s               \rvalid.txt           100%[===================>] 640.60K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-08-21 07:50:12 (27.2 MB/s) - ‘valid.txt’ saved [655979/655979]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read it to inspect it\n",
        "with open('valid.txt', 'r') as f:\n",
        "    valid = f.read()"
      ],
      "metadata": {
        "id": "zWlkO498xmlh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode validation dataset into a tensor\n",
        "valid_data = torch.tensor(encode(valid), dtype=torch.long)\n",
        "print(valid_data.shape, valid_data.type)\n",
        "print(valid_data[:100])\n",
        "\n",
        "# code from the repetitive cells above is ripe for a function"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eN33UQOxtW4",
        "outputId": "e10c9c5c-9a77-446f-8669-12331a49f322"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([652605]) <built-in method type of Tensor object at 0x7c85deec55e0>\n",
            "tensor([28,  1,  9, 10, 10,  1, 15, 10,  1,  5,  9,  2, 15,  2,  1, 17, 16, 21,\n",
            "        16,  7, 22,  1, 15,  2,  1, 26,  2,  1,  9,  2, 21,  2, 19, 10,  1,  9,\n",
            "         2, 20,  2,  1, 22, 12, 10, 27, 10, 15,  8,  2, 21, 10,  2,  1,  3,  2,\n",
            "         2,  5,  9, 10,  1, 26,  2,  1, 24,  2, 15,  2, 15,  4,  9, 10,  1, 24,\n",
            "         6, 15,  8, 10,  1, 24,  2, 15,  2,  1, 14,  2, 20,  9,  2, 12,  2,  1,\n",
            "        15,  2,  1, 22, 27,  2, 13,  6, 15,  5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training block size\n",
        "block_size = 8\n",
        "train_data[:block_size+1]\n",
        "# the transformer is not trained on the entire text but on blocks of text e.g. the above block size is 9 characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8zSalDTzo_p",
        "outputId": "5c4c0b1c-1f82-448b-f232-16849894bce4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([28,  1, 21,  2,  2, 19, 10,  7,  2])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size] # inputs to the transformer\n",
        "y = train_data[1:block_size+1] # next block size, it is offset by 1\n",
        "# iterating through the block size\n",
        "for t in range(block_size):\n",
        "  context = x[:t+1]\n",
        "  target = y[t]\n",
        "  print(f'when input is {context} the target: {target}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeviTeJVzo86",
        "outputId": "d46b6904-f207-44f4-f9fc-b50066413ef2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([28]) the target: 1\n",
            "when input is tensor([28,  1]) the target: 21\n",
            "when input is tensor([28,  1, 21]) the target: 2\n",
            "when input is tensor([28,  1, 21,  2]) the target: 2\n",
            "when input is tensor([28,  1, 21,  2,  2]) the target: 19\n",
            "when input is tensor([28,  1, 21,  2,  2, 19]) the target: 10\n",
            "when input is tensor([28,  1, 21,  2,  2, 19, 10]) the target: 7\n",
            "when input is tensor([28,  1, 21,  2,  2, 19, 10,  7]) the target: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 4 # how many independent sequences will we process in parallel?\n",
        "block_size = 8 # what is the maximum context length for predictions?\n",
        "\n",
        "def get_batch(split):\n",
        "  # generate a small batch of data of inputs x and targets y\n",
        "  data = train_data if split == 'train' else valid_data\n",
        "  ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  return x,y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs: ')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets: ')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('----------')\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "  for t in range(block_size): # time dimension\n",
        "    context = xb[b, :t+1]\n",
        "    target = yb[b,t]\n",
        "    print(f'when input is {context.tolist()} the target: {target}')"
      ],
      "metadata": {
        "id": "T79l6ytgZ8-h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c0736ca-be85-4de6-9e37-f694f487b2c2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs: \n",
            "torch.Size([4, 8])\n",
            "tensor([[12, 22, 13, 10, 14,  7,  2, 15],\n",
            "        [20, 10, 20, 10, 21, 10, 27,  2],\n",
            "        [11, 10,  1, 24,  2,  1, 21,  2],\n",
            "        [ 2, 16,  1, 27, 10, 21,  2, 12]])\n",
            "targets: \n",
            "torch.Size([4, 8])\n",
            "tensor([[22, 13, 10, 14,  7,  2, 15, 26],\n",
            "        [10, 20, 10, 21, 10, 27,  2,  1],\n",
            "        [10,  1, 24,  2,  1, 21,  2, 15],\n",
            "        [16,  1, 27, 10, 21,  2, 12,  2]])\n",
            "----------\n",
            "when input is [12] the target: 22\n",
            "when input is [12, 22] the target: 13\n",
            "when input is [12, 22, 13] the target: 10\n",
            "when input is [12, 22, 13, 10] the target: 14\n",
            "when input is [12, 22, 13, 10, 14] the target: 7\n",
            "when input is [12, 22, 13, 10, 14, 7] the target: 2\n",
            "when input is [12, 22, 13, 10, 14, 7, 2] the target: 15\n",
            "when input is [12, 22, 13, 10, 14, 7, 2, 15] the target: 26\n",
            "when input is [20] the target: 10\n",
            "when input is [20, 10] the target: 20\n",
            "when input is [20, 10, 20] the target: 10\n",
            "when input is [20, 10, 20, 10] the target: 21\n",
            "when input is [20, 10, 20, 10, 21] the target: 10\n",
            "when input is [20, 10, 20, 10, 21, 10] the target: 27\n",
            "when input is [20, 10, 20, 10, 21, 10, 27] the target: 2\n",
            "when input is [20, 10, 20, 10, 21, 10, 27, 2] the target: 1\n",
            "when input is [11] the target: 10\n",
            "when input is [11, 10] the target: 1\n",
            "when input is [11, 10, 1] the target: 24\n",
            "when input is [11, 10, 1, 24] the target: 2\n",
            "when input is [11, 10, 1, 24, 2] the target: 1\n",
            "when input is [11, 10, 1, 24, 2, 1] the target: 21\n",
            "when input is [11, 10, 1, 24, 2, 1, 21] the target: 2\n",
            "when input is [11, 10, 1, 24, 2, 1, 21, 2] the target: 15\n",
            "when input is [2] the target: 16\n",
            "when input is [2, 16] the target: 1\n",
            "when input is [2, 16, 1] the target: 27\n",
            "when input is [2, 16, 1, 27] the target: 10\n",
            "when input is [2, 16, 1, 27, 10] the target: 21\n",
            "when input is [2, 16, 1, 27, 10, 21] the target: 2\n",
            "when input is [2, 16, 1, 27, 10, 21, 2] the target: 12\n",
            "when input is [2, 16, 1, 27, 10, 21, 2, 12] the target: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(xb)"
      ],
      "metadata": {
        "id": "7Gl3V6Y8V--R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c81c57d-a731-4f14-c40e-3f504d04df10"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[12, 22, 13, 10, 14,  7,  2, 15],\n",
            "        [20, 10, 20, 10, 21, 10, 27,  2],\n",
            "        [11, 10,  1, 24,  2,  1, 21,  2],\n",
            "        [ 2, 16,  1, 27, 10, 21,  2, 12]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    # each token directly reads off the logits for the next token from a lookup table\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "\n",
        "  def forward(self, idx, targets=None):\n",
        "     # idx and targets are both (B,T) tensor of integers\n",
        "     logits = self.token_embedding_table(idx) # (Batch,Time,Channel) tensor\n",
        "\n",
        "     if targets is None:\n",
        "      loss = None\n",
        "     else:\n",
        "      B,T,C = logits.shape\n",
        "      logits = logits.view(B*T, C)\n",
        "      targets = targets.view(B*T)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "     return logits, loss\n",
        "\n",
        "  def generate(self, idx, max_new_tokens):\n",
        "    # idx is (B, T) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "      # get the predictions\n",
        "      logits, loss = self(idx)\n",
        "      # focus only on the last time step\n",
        "      logits = logits[:,-1,:] # becomes(B,C)\n",
        "      # apply softmax to get probabilities\n",
        "      probs = F.softmax(logits, dim=-1) # (B,C)\n",
        "      # sample from the distribution\n",
        "      idx_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
        "      # append sampled index to the running sequence\n",
        "      idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "    return idx\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "logits, loss = m(xb, yb)\n",
        "out = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "print(decode(m.generate(idx = torch.zeros((1,1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRNc43wfZYUe",
        "outputId": "0db1a3b1-f6fa-4731-8115-77c4cae59b28"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 29])\n",
            "tensor(4.0687, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "pvpv﻿nauzhklblpnnamd\n",
            "nkrhvgeh lkjrokmjrulbsbuzwna\n",
            "p\n",
            "qko\n",
            "enbromnabuzwcyrhmmnnhsnbxpsxmuowomabsv apitg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a pytorch optimiser object\n",
        "optimiser = torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "jwxascAYh2tN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "for steps in range(10000):\n",
        "  # sample a batch of data\n",
        "  xb, yb = get_batch('train')\n",
        "\n",
        "  # evaluate the loss\n",
        "  logits, loss = m(xb, yb)\n",
        "  optimiser.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimiser.step()\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npOuI2d9u1Lp",
        "outputId": "7aa32194-10aa-4b4a-e215-8eac8d55ab67"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0956337451934814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(m.generate(idx = torch.zeros((1,1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqBCaw_-u1JI",
        "outputId": "db32e142-a9d0-4279-8854-f35bc427e145"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  rushio kitanajanimilihu  ka zif nekiza uba nanama nalekwaada kuka da he ya shi kikwenao ga ba liji ya bwalo ha u ao ngo sti mimba mpando maja zo wanuna  vi sa ja ya mchana yoarisitatanda ansuoto kayawezobaweo nawekwahio towalivikuwa yafibotida yoni yoaa \n",
            " hekeku mea a msho  i ya a ka  hda wa m heria tali di kemkug kurekakusa wa zama waniyonanzartaria ho wali kawa kundirima \n",
            " nzemisi  ki hila ta ka cofa tikifa chenili ka mbotana letihio  \n",
            " snenicmsalimgi cha mya yosungoji wenya \n",
            " hizai mbafanik\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Much improvement on the Bigram model but we're not quite there yet. This is a simple model where the tokens are not talking to each other, where the prediction is happening only on the very last character. So next we have to make the tokens talk to each other and figure out the context and make better predictions which is what the **Transformer** will do."
      ],
      "metadata": {
        "id": "VSLB0F-N66Cd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RvTH9ATWh2qs"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}