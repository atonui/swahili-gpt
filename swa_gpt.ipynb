{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDLdJjYvroJsmjhm75TbK5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atonui/swahili-gpt/blob/main/swa_gpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Swahili-GPT\n",
        "- A simple character level transformer based LLM trained on a Swahili dataset."
      ],
      "metadata": {
        "id": "nZvhfs91jrcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the training dataset\n",
        "!wget https://raw.githubusercontent.com/atonui/pds/refs/heads/main/swahili_data/train.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-yFDZfe5QZ9",
        "outputId": "025f81f7-64e1-4a45-814e-2cf41c257d47"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-26 14:08:07--  https://raw.githubusercontent.com/atonui/pds/refs/heads/main/swahili_data/train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7564413 (7.2M) [text/plain]\n",
            "Saving to: ‘train.txt’\n",
            "\n",
            "train.txt           100%[===================>]   7.21M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-08-26 14:08:07 (56.1 MB/s) - ‘train.txt’ saved [7564413/7564413]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read it to inspect it\n",
        "with open('train.txt', 'r') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "UhB5WPU47Ou7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Length of dataset in characters: ', len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UxSd4krhuOa",
        "outputId": "02d081ce-cb9c-4c7b-a3fd-e7045d5ee6cd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of dataset in characters:  7522342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRigK2Eph4gQ",
        "outputId": "afd0ebfe-43d5-48a2-e8fb-b317c4226df5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿ taarifa hiyo ilisema kuwa ongezeko la joto la maji juu ya wastani katikati ya bahari ya  inaashiria kuwepo kwa mvua za el nino  hadi mwishoni mwa april ishirini moja sifuri imeelezwa kuwa ongezeko la joto magharibi mwa bahari ya hindi linatarajiwa kuhamia katikati ya bahari hiyo hali ambayo itasababisha pepo kutoka kaskazini mashariki kuvuma kuelekea bahari ya hindi \n",
            " aidha ilisema kuwa mwelekeo wa kupungua kwa joto kusini mashariki mwa bahari ya atlantic  kusababisha pepo kutoka magharibi kuvuma kuelekea magharibi mwa tanzania katika maeneo ya ziwa victoria \n",
            " mwelekeo wa mvua wa septemba hadi desemba ishirini sifuri tisa unatarajiwa kuwa katika namna tofauti ambapo baadhi ya maeneo yanaweza kunufaika huku mengine  \n",
            " ilifafanua kuwa msimu wa vuli  maeneo ambayo hupata mvua mara mbili ambayo ni kaskazini mwa nchi ikiwa ni nyanda za juu kaskazini mashariki kanda ya ziwa victoria na pwani ya kaskazini \n",
            " katika maeneo hayo mvua zinatarajiwa kunyesha wiki ya pili na tatu ya septemba mwaka\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get a sorted list of all the characters in the text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(\"There are\", vocab_size, \"unique characters in this text.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRhQYJhSh8q4",
        "outputId": "afc44596-e757-455f-cede-8332d3ebfd49"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " abcdefghijklmnopqrstuvwxyz﻿\n",
            "There are 29 unique characters in this text.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenisation\n",
        "- Represent characters as integers (vectors) so the model can manipulate them.\n",
        "- The below tokeniser is simple, it just translates a character to an integer.\n",
        "- There are more sophisticated tokenisers out there, we shall experiment with them."
      ],
      "metadata": {
        "id": "YJyI7xQQimZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "print(encode(\"joto jingi\"))\n",
        "print(decode(encode(\"joto jingi\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEcJKxRMiXo4",
        "outputId": "e27e26ee-cf87-46cb-b9a8-34f28013a417"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11, 16, 21, 16, 1, 11, 10, 15, 8, 10]\n",
            "joto jingi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode([14, 19, 24, 19, 1, 16, 17, 18, 11, 13]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSibstVvl-19",
        "outputId": "dbc37ce8-aea6-4cc0-9ad8-b906d8c69ba0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mrwr opqjl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we're going to encode the entire dataset and store it into a torch.Tensor\n",
        "import torch\n",
        "train_data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(train_data.shape, train_data.type,'\\n')\n",
        "print(train_data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzexWCVBnuuK",
        "outputId": "ea106f3f-cf4e-4178-840c-b1b4fa0bf02e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7522342]) <built-in method type of Tensor object at 0x78c93cc4b110> \n",
            "\n",
            "tensor([28,  1, 21,  2,  2, 19, 10,  7,  2,  1,  9, 10, 26, 16,  1, 10, 13, 10,\n",
            "        20,  6, 14,  2,  1, 12, 22, 24,  2,  1, 16, 15,  8,  6, 27,  6, 12, 16,\n",
            "         1, 13,  2,  1, 11, 16, 21, 16,  1, 13,  2,  1, 14,  2, 11, 10,  1, 11,\n",
            "        22, 22,  1, 26,  2,  1, 24,  2, 20, 21,  2, 15, 10,  1, 12,  2, 21, 10,\n",
            "        12,  2, 21, 10,  1, 26,  2,  1,  3,  2,  9,  2, 19, 10,  1, 26,  2,  1,\n",
            "         1, 10, 15,  2,  2, 20,  9, 10, 19, 10,  2,  1, 12, 22, 24,  6, 17, 16,\n",
            "         1, 12, 24,  2,  1, 14, 23, 22,  2,  1, 27,  2,  1,  6, 13,  1, 15, 10,\n",
            "        15, 16,  1,  1,  9,  2,  5, 10,  1, 14, 24, 10, 20,  9, 16, 15, 10,  1,\n",
            "        14, 24,  2,  1,  2, 17, 19, 10, 13,  1, 10, 20,  9, 10, 19, 10, 15, 10,\n",
            "         1, 14, 16, 11,  2,  1, 20, 10,  7, 22, 19, 10,  1, 10, 14,  6,  6, 13,\n",
            "         6, 27, 24,  2,  1, 12, 22, 24,  2,  1, 16, 15,  8,  6, 27,  6, 12, 16,\n",
            "         1, 13,  2,  1, 11, 16, 21, 16,  1, 14,  2,  8,  9,  2, 19, 10,  3, 10,\n",
            "         1, 14, 24,  2,  1,  3,  2,  9,  2, 19, 10,  1, 26,  2,  1,  9, 10, 15,\n",
            "         5, 10,  1, 13, 10, 15,  2, 21,  2, 19,  2, 11, 10, 24,  2,  1, 12, 22,\n",
            "         9,  2, 14, 10,  2,  1, 12,  2, 21, 10, 12,  2, 21, 10,  1, 26,  2,  1,\n",
            "         3,  2,  9,  2, 19, 10,  1,  9, 10, 26, 16,  1,  9,  2, 13, 10,  1,  2,\n",
            "        14,  3,  2, 26, 16,  1, 10, 21,  2, 20,  2,  3,  2,  3, 10, 20,  9,  2,\n",
            "         1, 17,  6, 17, 16,  1, 12, 22, 21, 16, 12,  2,  1, 12,  2, 20, 12,  2,\n",
            "        27, 10, 15, 10,  1, 14,  2, 20,  9,  2, 19, 10, 12, 10,  1, 12, 22, 23,\n",
            "        22, 14,  2,  1, 12, 22,  6, 13,  6, 12,  6,  2,  1,  3,  2,  9,  2, 19,\n",
            "        10,  1, 26,  2,  1,  9, 10, 15,  5, 10,  1,  0,  1,  2, 10,  5,  9,  2,\n",
            "         1, 10, 13, 10, 20,  6, 14,  2,  1, 12, 22, 24,  2,  1, 14, 24,  6, 13,\n",
            "         6, 12,  6, 16,  1, 24,  2,  1, 12, 22, 17, 22, 15,  8, 22,  2,  1, 12,\n",
            "        24,  2,  1, 11, 16, 21, 16,  1, 12, 22, 20, 10, 15, 10,  1, 14,  2, 20,\n",
            "         9,  2, 19, 10, 12, 10,  1, 14, 24,  2,  1,  3,  2,  9,  2, 19, 10,  1,\n",
            "        26,  2,  1,  2, 21, 13,  2, 15, 21, 10,  4,  1,  1, 12, 22, 20,  2,  3,\n",
            "         2,  3, 10, 20,  9,  2,  1, 17,  6, 17, 16,  1, 12, 22, 21, 16, 12,  2,\n",
            "         1, 14,  2,  8,  9,  2, 19, 10,  3, 10,  1, 12, 22, 23, 22, 14,  2,  1,\n",
            "        12, 22,  6, 13,  6, 12,  6,  2,  1, 14,  2,  8,  9,  2, 19, 10,  3, 10,\n",
            "         1, 14, 24,  2,  1, 21,  2, 15, 27,  2, 15, 10,  2,  1, 12,  2, 21, 10,\n",
            "        12,  2,  1, 14,  2,  6, 15,  6, 16,  1, 26,  2,  1, 27, 10, 24,  2,  1,\n",
            "        23, 10,  4, 21, 16, 19, 10,  2,  1,  0,  1, 14, 24,  6, 13,  6, 12,  6,\n",
            "        16,  1, 24,  2,  1, 14, 23, 22,  2,  1, 24,  2,  1, 20,  6, 17, 21,  6,\n",
            "        14,  3,  2,  1,  9,  2,  5, 10,  1,  5,  6, 20,  6, 14,  3,  2,  1, 10,\n",
            "        20,  9, 10, 19, 10, 15, 10,  1, 20, 10,  7, 22, 19, 10,  1, 21, 10, 20,\n",
            "         2,  1, 22, 15,  2, 21,  2, 19,  2, 11, 10, 24,  2,  1, 12, 22, 24,  2,\n",
            "         1, 12,  2, 21, 10, 12,  2,  1, 15,  2, 14, 15,  2,  1, 21, 16,  7,  2,\n",
            "        22, 21, 10,  1,  2, 14,  3,  2, 17, 16,  1,  3,  2,  2,  5,  9, 10,  1,\n",
            "        26,  2,  1, 14,  2,  6, 15,  6, 16,  1, 26,  2, 15,  2, 24,  6, 27,  2,\n",
            "         1, 12, 22, 15, 22,  7,  2, 10, 12,  2,  1,  9, 22, 12, 22,  1, 14,  6,\n",
            "        15,  8, 10, 15,  6,  1,  1,  0,  1, 10, 13, 10,  7,  2,  7,  2, 15, 22,\n",
            "         2,  1, 12, 22, 24,  2,  1, 14, 20, 10, 14, 22,  1, 24,  2,  1, 23, 22,\n",
            "        13, 10,  1,  1, 14,  2,  6, 15,  6, 16,  1,  2, 14,  3,  2, 26, 16,  1,\n",
            "         9, 22, 17,  2, 21,  2,  1, 14, 23, 22,  2,  1, 14,  2, 19,  2,  1, 14,\n",
            "         3, 10, 13, 10,  1,  2, 14,  3,  2, 26, 16,  1, 15, 10,  1, 12,  2, 20,\n",
            "        12,  2, 27, 10, 15, 10,  1, 14, 24,  2,  1, 15,  4,  9, 10,  1, 10, 12,\n",
            "        10, 24,  2,  1, 15, 10,  1, 15, 26,  2, 15,  5,  2,  1, 27,  2,  1, 11,\n",
            "        22, 22,  1, 12,  2, 20, 12,  2, 27, 10, 15, 10,  1, 14,  2, 20,  9,  2,\n",
            "        19, 10, 12, 10,  1, 12,  2, 15,  5,  2,  1, 26,  2,  1, 27, 10, 24,  2,\n",
            "         1, 23, 10,  4, 21, 16, 19, 10,  2,  1, 15,  2,  1, 17, 24,  2, 15, 10,\n",
            "         1, 26,  2,  1, 12,  2, 20, 12,  2, 27, 10, 15, 10,  1,  0,  1, 12,  2,\n",
            "        21, 10, 12,  2,  1, 14,  2,  6, 15,  6, 16,  1,  9,  2, 26, 16,  1, 14,\n",
            "        23, 22,  2,  1, 27, 10, 15,  2, 21,  2, 19,  2, 11, 10, 24,  2,  1, 12,\n",
            "        22, 15, 26,  6, 20,  9,  2,  1, 24, 10, 12, 10,  1, 26,  2,  1, 17, 10,\n",
            "        13, 10,  1, 15,  2,  1, 21,  2, 21, 22,  1, 26,  2,  1, 20,  6, 17, 21,\n",
            "         6, 14,  3,  2,  1, 14, 24,  2, 12,  2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test dataset\n",
        "!wget https://raw.githubusercontent.com/atonui/pds/refs/heads/main/swahili_data/test.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_LNLRnar98n",
        "outputId": "00cc13e0-7142-4fb7-ee6a-9912f7c31da9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-26 14:08:09--  https://raw.githubusercontent.com/atonui/pds/refs/heads/main/swahili_data/test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 686306 (670K) [text/plain]\n",
            "Saving to: ‘test.txt’\n",
            "\n",
            "test.txt            100%[===================>] 670.22K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-08-26 14:08:09 (8.45 MB/s) - ‘test.txt’ saved [686306/686306]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read it to inspect it\n",
        "with open('test.txt', 'r') as f:\n",
        "    test = f.read()"
      ],
      "metadata": {
        "id": "xuWYhPOLwF0T"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode test dataset into a tensor\n",
        "test_data = torch.tensor(encode(test), dtype=torch.long)\n",
        "print(test_data.shape, test_data.type, '\\n')\n",
        "print(test_data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMVNx7fVz_0_",
        "outputId": "7217b48b-1023-4a5f-e18d-3678c68551c0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([682933]) <built-in method type of Tensor object at 0x78ca1fa78e10> \n",
            "\n",
            "tensor([28,  1,  9, 22, 26, 16,  1,  2, 13, 10, 20, 10, 20, 10, 21, 10, 27,  2,\n",
            "         1, 12, 22, 24,  2,  1,  9,  2, 12, 22,  9, 16, 11, 10, 24,  2,  1,  3,\n",
            "         2, 13, 10,  1,  2, 13, 10, 17,  6, 24,  2,  1, 12,  2, 19,  2, 21,  2,\n",
            "        20, 10,  1, 21, 22, 17, 22,  1, 15,  2,  1, 12, 22, 21,  2, 12, 10, 24,\n",
            "         2,  1, 12, 22, 20,  2, 10, 15, 10,  1,  3, 10, 13,  2,  1, 12, 22,  7,\n",
            "         2,  9,  2, 14, 22,  1, 15, 10,  1, 12, 10, 21, 22,  1,  8,  2, 15, 10,\n",
            "         1,  1,  0,  1,  2, 12, 10,  6, 13,  6, 27,  6,  2,  1, 20, 10, 12, 22,\n",
            "         1, 26,  2,  1, 21, 22, 12, 10, 16,  1,  2, 13, 10, 20,  6, 14,  2,  1,\n",
            "         2, 13, 10, 17, 10,  8, 10, 24,  2,  1, 20, 10, 14, 22,  1, 15,  2,  1,\n",
            "        20, 20, 17,  1, 20,  2, 13, 22, 14,  1, 12, 10, 20,  2, 10,  1,  2, 14,\n",
            "         3,  2, 26,  6,  1,  2, 13, 10, 14, 21,  2, 12,  2,  1, 12, 22,  7, 10,\n",
            "        12,  2,  1, 12,  2, 21, 10, 12,  2,  1, 16,  7, 10, 20, 10,  1, 27,  2,\n",
            "         1, 21, 22, 14,  6,  1,  9, 10, 26, 16,  1, 15,  2,  1,  2, 13, 10,  7,\n",
            "        10, 12,  2,  1,  9,  2, 17, 16,  1, 16, 12, 21, 16,  3,  2,  1, 12, 22,\n",
            "        14, 10,  1, 14, 24,  2, 12,  2,  1, 11,  2, 15,  2,  1, 12, 22, 21,  6,\n",
            "        12,  6, 13,  6, 27,  2,  1,  2,  8, 10, 27, 16,  1, 13,  2,  1, 14, 17,\n",
            "         6, 13,  6, 13,  6, 27, 10,  1,  9, 22, 26, 16,  1,  0,  1,  2, 13, 10,\n",
            "         5,  2, 10,  1, 12, 22, 24,  2,  1,  3,  2,  2,  5,  2,  1, 26,  2,  1,\n",
            "        12, 22,  7, 10, 12,  2,  1,  9,  2, 17, 16,  1,  2, 13, 10,  2, 14,  3,\n",
            "        10, 24,  2,  1, 15,  2,  1,  3, 24,  2, 15,  2,  1, 12, 10, 20,  2, 10,\n",
            "         1, 12, 22, 24,  2,  1,  2, 15,  2,  9, 10, 21,  2, 11, 10,  1, 12, 22,\n",
            "         7,  2, 15, 26,  2,  1, 14,  2, 19,  6, 12,  6,  3, 10, 20,  9, 16,  1,\n",
            "        14,  2,  4,  9,  2,  4,  9,  6,  1, 12, 24,  6, 15, 26,  6,  1, 14,  2,\n",
            "         6, 13,  6, 27, 16,  1, 26,  2,  1, 21, 22,  9, 22, 14,  2,  1, 27,  2,\n",
            "        12,  6,  1,  9, 10, 23, 26, 16,  1,  2, 13, 10, 14, 17,  2,  1, 12,  2,\n",
            "        19,  2, 21,  2, 20, 10,  1, 21, 22, 17, 22,  1,  1, 15,  2,  1,  3,  2,\n",
            "         2,  5,  2, 26,  6,  1, 14, 17,  6, 13,  6, 13,  6, 27, 10,  1,  9, 22,\n",
            "        26, 16,  1,  2, 15,  8,  6,  2, 15,  5, 10, 12,  2,  1, 14,  2,  6, 13,\n",
            "         6, 27, 16,  1,  0,  1,  2, 13, 10,  5,  2, 10,  1, 12, 22, 24,  2,  1,\n",
            "        12,  2,  3, 13,  2,  1, 26,  2,  1, 12, 22, 21, 10,  2,  1, 20,  2, 10,\n",
            "        15, 10,  1,  2, 13, 10, 19, 22,  9, 22, 20, 10, 24,  2,  1, 12, 24,  6,\n",
            "        15,  5,  2,  1, 14, 20, 10, 12, 10, 21, 10, 15, 10,  1, 12, 22, 20, 24,\n",
            "         2, 13, 10,  1,  9, 10, 23, 26, 16,  1,  2, 13, 10, 16, 15,  5, 16, 12,\n",
            "         2,  1, 12, 22,  6, 13,  6, 12,  6,  2,  1, 14,  2,  6, 15,  6, 16,  1,\n",
            "        26,  2,  1, 14, 10, 12, 16,  4,  9,  6, 15, 10,  1,  5,  2, 19,  1,  6,\n",
            "        20,  1, 20,  2, 13,  2,  2, 14,  1,  0,  1, 20, 10, 21,  2, 20,  2,  9,\n",
            "         2, 22,  1, 12,  2, 21, 10, 12,  2,  1, 14,  2, 10, 20,  9,  2,  1, 26,\n",
            "         2, 15,  8, 22,  1, 15, 10,  1, 21, 22, 12, 10, 16,  1, 13,  2,  1,  2,\n",
            "        11,  2,  3, 22,  1,  2, 14,  3,  2, 13, 16,  1, 15, 10, 13, 10,  7,  2,\n",
            "        15, 26, 10, 24,  2,  1, 15, 10, 12, 10, 24,  2,  1, 14, 20, 10, 12, 10,\n",
            "        21, 10, 15, 10,  1,  2, 13, 10, 12, 22, 11,  2,  1, 16,  7, 10, 20,  2,\n",
            "         1, 14, 14, 16, 11,  2,  1, 24,  2,  1, 21, 22, 14,  6,  1, 15,  2,  1,\n",
            "        12, 22, 15, 10, 21,  2, 12,  2,  1, 15, 10,  6, 15,  5,  6,  1, 16,  7,\n",
            "        10, 20, 10,  1, 27,  2, 16,  1,  9, 22, 12, 22,  1, 14, 21, 16,  2,  1,\n",
            "         9, 16, 21, 22,  3,  2,  1,  2, 12, 10, 24,  2,  1,  2, 14,  6, 17,  2,\n",
            "        15,  5,  2,  1,  6, 15,  6, 16,  1, 13,  2,  1, 12, 22, 21, 16, 13,  6,\n",
            "         2,  1,  9, 16, 21, 22,  3,  2,  1,  9, 10, 26, 16,  1, 12, 24,  2,  1,\n",
            "        24,  2, 10, 20, 13,  2, 14,  1, 15,  5, 10,  4,  9, 16,  1, 12, 10, 21,\n",
            "        22,  1, 14, 22,  9, 10, 14, 22,  1, 20,  2, 15,  2,  1,  2, 13, 10,  5,\n",
            "         2, 10,  1,  3, 24,  2, 15,  2,  1,  7,  2, 19, 10, 11,  2, 13,  2,  1,\n",
            "         0,  1,  2, 13, 10,  5,  2, 10,  1, 12, 22, 24,  2,  1,  3,  2,  2,  5,\n",
            "         2,  1, 26,  2,  1, 12, 22,  7, 10, 12,  2,  1, 12,  2, 21, 10, 12,  2,\n",
            "         1, 21, 22, 14,  6,  1,  9, 10, 26, 16,  1,  2, 13, 10, 17,  6, 24,  2,\n",
            "         1, 12,  2, 19,  2, 21,  2, 20, 10,  1, 27, 10, 13,  6,  1, 27, 10, 13,\n",
            "         6,  1, 15,  2,  1, 12, 22,  2, 14,  3, 10, 24,  2,  1,  2, 20,  2, 10,\n",
            "        15, 10,  1, 10, 13, 10,  1,  2, 24,  6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# validation dataset\n",
        "!wget https://raw.githubusercontent.com/atonui/pds/refs/heads/main/swahili_data/valid.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn8P7PFyxfkp",
        "outputId": "9f318cd2-80a4-498a-e524-eb47ee5d5183"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-26 14:08:09--  https://raw.githubusercontent.com/atonui/pds/refs/heads/main/swahili_data/valid.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 655979 (641K) [text/plain]\n",
            "Saving to: ‘valid.txt’\n",
            "\n",
            "valid.txt           100%[===================>] 640.60K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-08-26 14:08:10 (8.24 MB/s) - ‘valid.txt’ saved [655979/655979]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read it to inspect it\n",
        "with open('valid.txt', 'r') as f:\n",
        "    valid = f.read()"
      ],
      "metadata": {
        "id": "zWlkO498xmlh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode validation dataset into a tensor\n",
        "valid_data = torch.tensor(encode(valid), dtype=torch.long)\n",
        "print(valid_data.shape, valid_data.type)\n",
        "print(valid_data[:100])\n",
        "\n",
        "# code from the repetitive cells above is ripe for a function"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eN33UQOxtW4",
        "outputId": "8f276020-fb0c-4f21-aa57-a1480b7021ba"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([652605]) <built-in method type of Tensor object at 0x78ca1fa784b0>\n",
            "tensor([28,  1,  9, 10, 10,  1, 15, 10,  1,  5,  9,  2, 15,  2,  1, 17, 16, 21,\n",
            "        16,  7, 22,  1, 15,  2,  1, 26,  2,  1,  9,  2, 21,  2, 19, 10,  1,  9,\n",
            "         2, 20,  2,  1, 22, 12, 10, 27, 10, 15,  8,  2, 21, 10,  2,  1,  3,  2,\n",
            "         2,  5,  9, 10,  1, 26,  2,  1, 24,  2, 15,  2, 15,  4,  9, 10,  1, 24,\n",
            "         6, 15,  8, 10,  1, 24,  2, 15,  2,  1, 14,  2, 20,  9,  2, 12,  2,  1,\n",
            "        15,  2,  1, 22, 27,  2, 13,  6, 15,  5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training block size\n",
        "block_size = 8\n",
        "train_data[:block_size+1]\n",
        "# the transformer is not trained on the entire text but on blocks of text e.g. the above block size is 9 characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8zSalDTzo_p",
        "outputId": "07142ebb-1419-48ed-a5e1-b9f0a8aeb4d9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([28,  1, 21,  2,  2, 19, 10,  7,  2])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size] # inputs to the transformer\n",
        "y = train_data[1:block_size+1] # next block size, it is offset by 1\n",
        "# iterating through the block size\n",
        "for t in range(block_size):\n",
        "  context = x[:t+1]\n",
        "  target = y[t]\n",
        "  print(f'when input is {context} the target: {target}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeviTeJVzo86",
        "outputId": "f8d6e395-76b9-4a03-d563-5e2f0c7de374"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([28]) the target: 1\n",
            "when input is tensor([28,  1]) the target: 21\n",
            "when input is tensor([28,  1, 21]) the target: 2\n",
            "when input is tensor([28,  1, 21,  2]) the target: 2\n",
            "when input is tensor([28,  1, 21,  2,  2]) the target: 19\n",
            "when input is tensor([28,  1, 21,  2,  2, 19]) the target: 10\n",
            "when input is tensor([28,  1, 21,  2,  2, 19, 10]) the target: 7\n",
            "when input is tensor([28,  1, 21,  2,  2, 19, 10,  7]) the target: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 4 # how many independent sequences will we process in parallel?\n",
        "block_size = 8 # what is the maximum context length for predictions?\n",
        "\n",
        "def get_batch(split):\n",
        "  # generate a small batch of data of inputs x and targets y\n",
        "  data = train_data if split == 'train' else valid_data\n",
        "  ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  return x,y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs: ')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets: ')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('----------')\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "  for t in range(block_size): # time dimension\n",
        "    context = xb[b, :t+1]\n",
        "    target = yb[b,t]\n",
        "    print(f'when input is {context.tolist()} the target: {target}')"
      ],
      "metadata": {
        "id": "T79l6ytgZ8-h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de4fe5cf-d5c5-4802-b0da-630dff768647"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs: \n",
            "torch.Size([4, 8])\n",
            "tensor([[12, 22, 13, 10, 14,  7,  2, 15],\n",
            "        [20, 10, 20, 10, 21, 10, 27,  2],\n",
            "        [11, 10,  1, 24,  2,  1, 21,  2],\n",
            "        [ 2, 16,  1, 27, 10, 21,  2, 12]])\n",
            "targets: \n",
            "torch.Size([4, 8])\n",
            "tensor([[22, 13, 10, 14,  7,  2, 15, 26],\n",
            "        [10, 20, 10, 21, 10, 27,  2,  1],\n",
            "        [10,  1, 24,  2,  1, 21,  2, 15],\n",
            "        [16,  1, 27, 10, 21,  2, 12,  2]])\n",
            "----------\n",
            "when input is [12] the target: 22\n",
            "when input is [12, 22] the target: 13\n",
            "when input is [12, 22, 13] the target: 10\n",
            "when input is [12, 22, 13, 10] the target: 14\n",
            "when input is [12, 22, 13, 10, 14] the target: 7\n",
            "when input is [12, 22, 13, 10, 14, 7] the target: 2\n",
            "when input is [12, 22, 13, 10, 14, 7, 2] the target: 15\n",
            "when input is [12, 22, 13, 10, 14, 7, 2, 15] the target: 26\n",
            "when input is [20] the target: 10\n",
            "when input is [20, 10] the target: 20\n",
            "when input is [20, 10, 20] the target: 10\n",
            "when input is [20, 10, 20, 10] the target: 21\n",
            "when input is [20, 10, 20, 10, 21] the target: 10\n",
            "when input is [20, 10, 20, 10, 21, 10] the target: 27\n",
            "when input is [20, 10, 20, 10, 21, 10, 27] the target: 2\n",
            "when input is [20, 10, 20, 10, 21, 10, 27, 2] the target: 1\n",
            "when input is [11] the target: 10\n",
            "when input is [11, 10] the target: 1\n",
            "when input is [11, 10, 1] the target: 24\n",
            "when input is [11, 10, 1, 24] the target: 2\n",
            "when input is [11, 10, 1, 24, 2] the target: 1\n",
            "when input is [11, 10, 1, 24, 2, 1] the target: 21\n",
            "when input is [11, 10, 1, 24, 2, 1, 21] the target: 2\n",
            "when input is [11, 10, 1, 24, 2, 1, 21, 2] the target: 15\n",
            "when input is [2] the target: 16\n",
            "when input is [2, 16] the target: 1\n",
            "when input is [2, 16, 1] the target: 27\n",
            "when input is [2, 16, 1, 27] the target: 10\n",
            "when input is [2, 16, 1, 27, 10] the target: 21\n",
            "when input is [2, 16, 1, 27, 10, 21] the target: 2\n",
            "when input is [2, 16, 1, 27, 10, 21, 2] the target: 12\n",
            "when input is [2, 16, 1, 27, 10, 21, 2, 12] the target: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(xb)"
      ],
      "metadata": {
        "id": "7Gl3V6Y8V--R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13f7415a-a85d-4e2e-f135-796e27407b24"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[12, 22, 13, 10, 14,  7,  2, 15],\n",
            "        [20, 10, 20, 10, 21, 10, 27,  2],\n",
            "        [11, 10,  1, 24,  2,  1, 21,  2],\n",
            "        [ 2, 16,  1, 27, 10, 21,  2, 12]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    # each token directly reads off the logits for the next token from a lookup table\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "\n",
        "  def forward(self, idx, targets=None):\n",
        "     # idx and targets are both (B,T) tensor of integers\n",
        "     logits = self.token_embedding_table(idx) # (Batch,Time,Channel) tensor\n",
        "\n",
        "     if targets is None:\n",
        "      loss = None\n",
        "     else:\n",
        "      B,T,C = logits.shape\n",
        "      logits = logits.view(B*T, C)\n",
        "      targets = targets.view(B*T)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "     return logits, loss\n",
        "\n",
        "  def generate(self, idx, max_new_tokens):\n",
        "    # idx is (B, T) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "      # get the predictions\n",
        "      logits, loss = self(idx)\n",
        "      # focus only on the last time step\n",
        "      logits = logits[:,-1,:] # becomes(B,C)\n",
        "      # apply softmax to get probabilities\n",
        "      probs = F.softmax(logits, dim=-1) # (B,C)\n",
        "      # sample from the distribution\n",
        "      idx_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
        "      # append sampled index to the running sequence\n",
        "      idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "    return idx\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "logits, loss = m(xb, yb)\n",
        "out = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "print(decode(m.generate(idx = torch.zeros((1,1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRNc43wfZYUe",
        "outputId": "8ae0a51a-5bae-443b-d880-98eb9633669b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 29])\n",
            "tensor(4.0687, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "pvpv﻿nauzhklblpnnamd\n",
            "nkrhvgeh lkjrokmjrulbsbuzwna\n",
            "p\n",
            "qko\n",
            "enbromnabuzwcyrhmmnnhsnbxpsxmuowomabsv apitg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a pytorch optimiser object\n",
        "optimiser = torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "jwxascAYh2tN"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "for steps in range(10000):\n",
        "  # sample a batch of data\n",
        "  xb, yb = get_batch('train')\n",
        "\n",
        "  # evaluate the loss\n",
        "  logits, loss = m(xb, yb)\n",
        "  optimiser.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimiser.step()\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npOuI2d9u1Lp",
        "outputId": "78eda93c-b447-4f24-971f-c173e59d70dc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0706610679626465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(m.generate(idx = torch.zeros((1,1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqBCaw_-u1JI",
        "outputId": "51b627dc-83f1-46e1-cad9-faea9ffeb83a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " wikena ku ngakuuku hali wengezinamishi chukujemi kime teofarai kaso wa hamendojishaizani weshe waluamasamatisilao es yekenuwa bandawa na datuna norika ma dupaza wananaya wa a junato kemsta stezesehimuuzit mwa tokijemosi shitaji hihaikamkika ya uwa sheetochio kakumemavikika hala wabe we kunggo ki mokikana vipi \n",
            " na kibamaturamao wayara \n",
            " ilika uakali m ko vya dinyabunza a ku gi ngujaliamda kia li mu kazo  wale ba  nginctuifanda aoa bi sema wakiku ma zuni hatata ta ativishari li  wani po ha wikia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Much improvement on the Bigram model but we're not quite there yet. This is a simple model where the tokens are not talking to each other, where the prediction is happening only on the very last character. So next we have to make the tokens talk to each other and figure out the context and make better predictions which is what the **Transformer** will do."
      ],
      "metadata": {
        "id": "VSLB0F-N66Cd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Mathematical trick in self attention"
      ],
      "metadata": {
        "id": "pQA-s46qDoDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "B, T, C = 4,8,2 # batch, time and channels (infomation)\n",
        "x = torch.randn(B,T,C)\n",
        "x.shape"
      ],
      "metadata": {
        "id": "RvTH9ATWh2qs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c207c79-ab13-400b-c6c9-57dbca1d51b6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 1\n",
        "xbow = torch.zeros((B, T, C)) # xbow -> x bag of words i.e. average. Initialise the tensor to all zeros\n",
        "for b in range(B):\n",
        "  for t in range(T):\n",
        "    xprev = x[b, :t+1] # (t,C)\n",
        "    xbow[b,t] = torch.mean(xprev, 0)"
      ],
      "metadata": {
        "id": "oMtWtptWEAna"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pbf7zAWG785B",
        "outputId": "e24c8d45-c575-49f2-d055-522ca811a675"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1808, -0.0700],\n",
              "        [-0.3596, -0.9152],\n",
              "        [ 0.6258,  0.0255],\n",
              "        [ 0.9545,  0.0643],\n",
              "        [ 0.3612,  1.1679],\n",
              "        [-1.3499, -0.5102],\n",
              "        [ 0.2360, -0.2398],\n",
              "        [-0.9211,  1.5433]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ROuiDg-70eK",
        "outputId": "69ca55cf-029e-4e14-d8bc-106acb384f2e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1808, -0.0700],\n",
              "        [-0.0894, -0.4926],\n",
              "        [ 0.1490, -0.3199],\n",
              "        [ 0.3504, -0.2238],\n",
              "        [ 0.3525,  0.0545],\n",
              "        [ 0.0688, -0.0396],\n",
              "        [ 0.0927, -0.0682],\n",
              "        [-0.0341,  0.1332]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see in the xbow[0] results that the piece of code is averaging out the column, row by row but it is very inefficient."
      ],
      "metadata": {
        "id": "rWXVC4jo8VfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "a = torch.ones(3,3)\n",
        "b = torch.randint(0,10,(3,2)).float()\n",
        "c = a @ b\n",
        "print('a=')\n",
        "print(a)\n",
        "print('------')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('------')\n",
        "print('c= a x b')\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8EI_7nH70hD",
        "outputId": "383177ca-4d6b-4593-f3e8-dbf0e16ff7d5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "------\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "------\n",
            "c= a x b\n",
            "tensor([[14., 16.],\n",
            "        [14., 16.],\n",
            "        [14., 16.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tril(torch.ones(3,3)) # triangular matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jenMNsI89oEh",
        "outputId": "2551d7ff-60af-4338-892b-2e802c950811"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [1., 1., 0.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "a = torch.tril(torch.ones(3,3)) # ---> make a, a triangular matrix\n",
        "b = torch.randint(0,10,(3,2)).float()\n",
        "c = a @ b # ---> matrix dot product\n",
        "print('a=')\n",
        "print(a)\n",
        "print('------')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('------')\n",
        "print('c= a x b')\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhqi7L2VDm0V",
        "outputId": "efb5af70-347a-4c93-8c5e-ae69c410ea4a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1., 0., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 1.]])\n",
            "------\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "------\n",
            "c= a x b\n",
            "tensor([[ 2.,  7.],\n",
            "        [ 8., 11.],\n",
            "        [14., 16.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the triangulat matrix, we can see that we are now doing sums of the tensors a and b. Therefore we can now do averages."
      ],
      "metadata": {
        "id": "bwIMn9a5K5WY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normalise a so that a row equals 1 then we can get the average when we do a dot product\n",
        "torch.manual_seed(42)\n",
        "a = torch.tril(torch.ones(3,3)) # ---> make a a triangular matrix, this matrix is like the weights\n",
        "a = a / torch.sum(a, 1, keepdim=True) # normalise a\n",
        "b = torch.randint(0,10,(3,2)).float()\n",
        "c = a @ b # ---> matrix dot product\n",
        "print('a=')\n",
        "print(a)\n",
        "print('------')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('------')\n",
        "print('c= a x b')\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAO2LML_EZSB",
        "outputId": "4a2e898d-d9b5-490c-d59b-c518ff61ecf5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "------\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "------\n",
            "c= a x b\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000],\n",
            "        [4.6667, 5.3333]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now back to our bag of words original problem."
      ],
      "metadata": {
        "id": "5rg1Tm9aO5ep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now vectorise the for loop to make it much more efficient."
      ],
      "metadata": {
        "id": "gMGhLu4BfQmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# version 2 --> using triangular matrices\n",
        "a2 = torch.tril(torch.ones(T,T))\n",
        "a2 = a2 / a2.sum(1, keepdim=True)\n",
        "a2"
      ],
      "metadata": {
        "id": "eBTs8ubFLEhg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be04dbee-f1ea-4394-8d92-f8985df4d82a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
              "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
              "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow2 = a2 @ x # (B,T,T) @ (B,T,C) ---> (B,T,C)\n",
        "xbow2"
      ],
      "metadata": {
        "id": "tQCcuJd1LEem",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "851dba47-8137-4ab9-8449-e0db5fd1b947"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.8173,  0.4127],\n",
              "         [-0.1342,  0.4395],\n",
              "         [ 0.2711,  0.4774],\n",
              "         [ 0.2421,  0.0694],\n",
              "         [ 0.0084,  0.0020],\n",
              "         [ 0.0712, -0.1128],\n",
              "         [ 0.2527,  0.2149]],\n",
              "\n",
              "        [[-0.6631, -0.2513],\n",
              "         [ 0.1735, -0.0649],\n",
              "         [ 0.1685,  0.3348],\n",
              "         [-0.1621,  0.1765],\n",
              "         [-0.2312, -0.0436],\n",
              "         [-0.1015, -0.2855],\n",
              "         [-0.2593, -0.1630],\n",
              "         [-0.3015, -0.2293]],\n",
              "\n",
              "        [[ 1.6455, -0.8030],\n",
              "         [ 1.4985, -0.5395],\n",
              "         [ 0.4954,  0.3420],\n",
              "         [ 1.0623, -0.1802],\n",
              "         [ 1.1401, -0.4462],\n",
              "         [ 1.0870, -0.4071],\n",
              "         [ 1.0430, -0.1299],\n",
              "         [ 1.1138, -0.1641]]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.allclose(xbow, xbow2, atol=1e-4) # https://stackoverflow.com/questions/75622268/comparing-two-tensors-in-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJii9OLjgoWi",
        "outputId": "9601f405-b87d-4db7-8fdb-6dd677e47b3f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow[0], xbow2[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctKbiXH-hatw",
        "outputId": "3844f239-6608-4fdb-ecc2-efcc66e88eb1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]]),\n",
              " tensor([[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]]))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The for loop and matrix operations give us the same answers but the matrix operation is much more efficient."
      ],
      "metadata": {
        "id": "ey62bD8VqrsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# version 3 ---> using softmax\n",
        "tril = torch.tril(torch.ones(T,T)) # --> this is a triangular matrix\n",
        "a3 = torch.zeros((B,T,T)) # --> this is a zero matrix\n",
        "a3 = a3.masked_fill(tril == 0, float('-inf')) # --> wherever there is a 0 in the tril matrix, replace with -inf(infinity) in the a3 matrix\n",
        "a3 = F.softmax(a3, dim=-1) # --> normalises each row of the matrix, just like a2 = a2 / a2.sum(1, keepdim=True) this operation does\n",
        "xbow3 = a3 @ x\n",
        "torch.allclose(xbow, xbow3, atol=1e-4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdZIjiuUqq8C",
        "outputId": "0fbcb299-5494-48a5-d20d-8fe110180cf0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a3[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVdad9bAySIP",
        "outputId": "9e8cf056-2635-45c3-84d4-699d79303c5c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
              "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
              "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tril"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3bxLz7AyE3-",
        "outputId": "edaab70b-7af6-463d-a33f-f4fb9f39f59a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a4 = torch.zeros((B,T,T))\n",
        "a4 = a4.masked_fill(tril == 0, float('-inf'))\n",
        "a4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqAyHkLcJo_v",
        "outputId": "b20dabcf-9365-49e7-de59-a66399a02ca6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
              "         [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
              "         [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
              "         [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
              "         [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
              "         [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
              "         [0., 0., 0., 0., 0., 0., 0., -inf],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
              "         [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
              "         [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
              "         [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
              "         [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
              "         [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
              "         [0., 0., 0., 0., 0., 0., 0., -inf],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
              "         [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
              "         [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
              "         [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
              "         [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
              "         [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
              "         [0., 0., 0., 0., 0., 0., 0., -inf],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
              "         [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
              "         [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
              "         [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
              "         [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
              "         [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
              "         [0., 0., 0., 0., 0., 0., 0., -inf],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self attention"
      ],
      "metadata": {
        "id": "j_hgA_LLmk7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# version 4: self attention\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,32 # batch, time and channels\n",
        "x = torch.randn(B,T,C)\n",
        "# single Head self attention\n",
        "head_size = 16\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)\n",
        "\n",
        "k = key(x) # (B,T,16)\n",
        "q = query(x) # (B,T,16)\n",
        "\n",
        "a4 = q @ k.transpose(-2, -1) # (B,T,16) @ (B,16,T) ---> (B,T,T)\n",
        "tril = torch.tril(torch.ones(T,T))\n",
        "# a4 = torch.zeros((T,T))\n",
        "a4 = a4.masked_fill(tril == 0, float('-inf')) # the future cannot communicate to the past\n",
        "a4 = F.softmax(a4, dim=1)\n",
        "\n",
        "v = value(x)\n",
        "out = a4 @ v\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tUSf6brxx3E",
        "outputId": "5be73ee9-c82b-4fe1-d05d-9a0220f29cbf"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a4[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5QW7zY4hbXF",
        "outputId": "dffca4e9-8a80-4a7e-d2a1-96c03c4f83cb"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0248, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0052, 0.0091, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0521, 0.0135, 0.2482, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3171, 0.0214, 0.1642, 0.1188, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0412, 0.0487, 0.1046, 0.0742, 0.2000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1060, 0.5347, 0.2059, 0.1030, 0.7402, 0.0192, 0.0000, 0.0000],\n",
              "        [0.4298, 0.3409, 0.1769, 0.2027, 0.0480, 0.8472, 0.2329, 0.0000],\n",
              "        [0.0238, 0.0316, 0.1002, 0.5013, 0.0117, 0.1336, 0.7671, 1.0000]],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every single token at each position will emit 2 vectors:\n",
        "- A Query vector: what am I looking for?\n",
        "- Key vector: What do I contain?\n",
        "We get the afinities between these tokens by doing a dot product of the keys and queries i.e. my Q dot K of all the other keys of all the other tokens.\n",
        "$$𝐖 = {𝐐}⋅{Κ} → weights (a\\: in\\: our\\: code)$$\n",
        "If the Q and K of two characters are aligned, they will interact to a very high amount so I will learn more about that token as opposed to other tokens.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mcAuNlF8M3HP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8bUryzV-MyZD"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wotfpEdUeM0v"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jB9Bs9iqeMx-"
      },
      "execution_count": 46,
      "outputs": []
    }
  ]
}